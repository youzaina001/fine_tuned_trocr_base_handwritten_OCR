{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ea3a50",
   "metadata": {
    "id": "50ea3a50"
   },
   "source": [
    "# Model Training Script\n",
    "This notebook is a transformation of the provided Python script into a Jupyter notebook. The script is designed for training a VisionEncoderDecoderModel using a custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "kXK0WIFwhI6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6013,
     "status": "ok",
     "timestamp": 1724758905347,
     "user": {
      "displayName": "Yassine Ouzaina",
      "userId": "01912818402851798301"
     },
     "user_tz": -120
    },
    "id": "kXK0WIFwhI6d",
    "outputId": "765b754b-2f27-4e9e-e6ba-824628ba9153",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (2.21.0)\n",
      "Requirement already satisfied: torch in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (2.4.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: streamlit in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (1.37.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (0.112.2)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (0.30.6)\n",
      "Requirement already satisfied: accelerate in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (0.33.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from torch) (73.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (5.4.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (5.27.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from streamlit) (4.0.2)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from fastapi) (0.38.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from fastapi) (2.8.2)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.1.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.5.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from starlette<0.39.0,>=0.37.2->fastapi) (4.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.3.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached h5py-3.11.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.0-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (73.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading grpcio-1.66.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.12.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yassine\\downloads\\e-learning\\fine_tuned_trocr_base_handwritten_ocrbench\\ocr_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl (385.2 MB)\n",
      "   ---------------------------------------- 0.0/385.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.1/385.2 MB 15.4 MB/s eta 0:00:25\n",
      "    --------------------------------------- 6.3/385.2 MB 14.9 MB/s eta 0:00:26\n",
      "    --------------------------------------- 9.4/385.2 MB 15.4 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 13.1/385.2 MB 15.5 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 16.5/385.2 MB 15.8 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 20.2/385.2 MB 15.9 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 23.6/385.2 MB 16.2 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 26.7/385.2 MB 16.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 30.1/385.2 MB 16.2 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 33.8/385.2 MB 16.3 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 37.5/385.2 MB 16.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 40.6/385.2 MB 16.3 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 44.0/385.2 MB 16.3 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 47.7/385.2 MB 16.3 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 51.4/385.2 MB 16.4 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 54.5/385.2 MB 16.3 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 57.7/385.2 MB 16.3 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 61.3/385.2 MB 16.3 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 64.7/385.2 MB 16.3 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 67.9/385.2 MB 16.3 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 71.3/385.2 MB 16.3 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 74.7/385.2 MB 16.3 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 78.4/385.2 MB 16.3 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 82.1/385.2 MB 16.4 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 85.7/385.2 MB 16.4 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 88.9/385.2 MB 16.3 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 92.8/385.2 MB 16.4 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 96.5/385.2 MB 16.4 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 99.9/385.2 MB 16.4 MB/s eta 0:00:18\n",
      "   ---------- ---------------------------- 103.5/385.2 MB 16.4 MB/s eta 0:00:18\n",
      "   ---------- ---------------------------- 106.7/385.2 MB 16.5 MB/s eta 0:00:17\n",
      "   ----------- --------------------------- 110.4/385.2 MB 16.5 MB/s eta 0:00:17\n",
      "   ----------- --------------------------- 113.8/385.2 MB 16.5 MB/s eta 0:00:17\n",
      "   ----------- --------------------------- 117.4/385.2 MB 16.5 MB/s eta 0:00:17\n",
      "   ------------ -------------------------- 121.1/385.2 MB 16.5 MB/s eta 0:00:16\n",
      "   ------------ -------------------------- 124.8/385.2 MB 16.5 MB/s eta 0:00:16\n",
      "   ------------ -------------------------- 127.9/385.2 MB 16.5 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 131.3/385.2 MB 16.5 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 135.0/385.2 MB 16.6 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 138.4/385.2 MB 16.6 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 142.1/385.2 MB 16.5 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 145.5/385.2 MB 16.5 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 148.9/385.2 MB 16.5 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 152.3/385.2 MB 16.5 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 155.5/385.2 MB 16.5 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 158.6/385.2 MB 16.5 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 162.3/385.2 MB 16.5 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 165.7/385.2 MB 16.5 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 169.3/385.2 MB 16.5 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 172.5/385.2 MB 16.5 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 175.9/385.2 MB 16.4 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 179.3/385.2 MB 16.5 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 182.5/385.2 MB 16.4 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 186.1/385.2 MB 16.4 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 189.3/385.2 MB 16.4 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 192.7/385.2 MB 16.4 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 196.1/385.2 MB 16.4 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 197.9/385.2 MB 16.3 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 200.8/385.2 MB 16.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 203.9/385.2 MB 16.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 205.5/385.2 MB 16.1 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 207.6/385.2 MB 16.0 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 211.6/385.2 MB 16.0 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 215.0/385.2 MB 16.0 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 218.1/385.2 MB 16.0 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 221.8/385.2 MB 16.0 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 225.4/385.2 MB 16.0 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 228.9/385.2 MB 16.0 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 232.3/385.2 MB 16.0 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 235.7/385.2 MB 16.0 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 239.1/385.2 MB 16.0 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 242.7/385.2 MB 16.0 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 246.4/385.2 MB 16.1 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 249.6/385.2 MB 16.1 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 253.2/385.2 MB 16.1 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 256.9/385.2 MB 16.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 260.3/385.2 MB 16.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 264.0/385.2 MB 16.1 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 267.4/385.2 MB 16.1 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 271.3/385.2 MB 16.1 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 274.7/385.2 MB 16.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ---------- 278.4/385.2 MB 16.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ---------- 281.3/385.2 MB 16.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ---------- 284.4/385.2 MB 16.1 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 288.1/385.2 MB 16.1 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 291.5/385.2 MB 16.1 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 295.2/385.2 MB 16.1 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 298.6/385.2 MB 16.1 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 302.3/385.2 MB 16.1 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 305.7/385.2 MB 16.1 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 309.1/385.2 MB 16.1 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 312.5/385.2 MB 16.1 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 315.9/385.2 MB 16.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 319.6/385.2 MB 16.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 323.0/385.2 MB 16.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 326.4/385.2 MB 16.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 329.5/385.2 MB 16.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 331.6/385.2 MB 16.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 334.5/385.2 MB 16.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 336.9/385.2 MB 15.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 340.0/385.2 MB 15.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 343.7/385.2 MB 15.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 346.8/385.2 MB 15.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 349.4/385.2 MB 15.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 352.6/385.2 MB 15.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 354.4/385.2 MB 15.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 357.0/385.2 MB 15.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 359.7/385.2 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 362.0/385.2 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 364.4/385.2 MB 15.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 366.7/385.2 MB 15.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 369.1/385.2 MB 15.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 372.0/385.2 MB 15.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 374.9/385.2 MB 15.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  378.0/385.2 MB 15.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  380.9/385.2 MB 15.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.5/385.2 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 385.2/385.2 MB 14.7 MB/s eta 0:00:00\n",
      "Downloading tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 15.1 MB/s eta 0:00:00\n",
      "Using cached h5py-3.11.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 14.3 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 13.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.8/26.4 MB 14.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.9/26.4 MB 15.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.5/26.4 MB 14.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.4/26.4 MB 12.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.3/26.4 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 19.1/26.4 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.4/26.4 MB 12.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.3/26.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 12.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.0-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 16.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 15.3 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp312-cp312-win_amd64.whl (267 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, astunparse, keras, tensorflow-intel, tensorflow, tf-keras\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.27.3\n",
      "    Uninstalling protobuf-5.27.3:\n",
      "      Successfully uninstalled protobuf-5.27.3\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.0 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.4 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 termcolor-2.4.0 tf-keras-2.17.0 werkzeug-3.0.4 wheel-0.44.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch torchvision streamlit fastapi uvicorn accelerate sentencepiece\n",
    "!pip install tensorflow tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "FmJt7OQLjz2F",
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1724758907277,
     "user": {
      "displayName": "Yassine Ouzaina",
      "userId": "01912818402851798301"
     },
     "user_tz": -120
    },
    "id": "FmJt7OQLjz2F",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b50fa08f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24472,
     "status": "ok",
     "timestamp": 1724758934201,
     "user": {
      "displayName": "Yassine Ouzaina",
      "userId": "01912818402851798301"
     },
     "user_tz": -120
    },
    "id": "b50fa08f",
    "outputId": "d3faa4da-721c-4dec-e845-cf684053831c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import gc\n",
    "\n",
    "# Checking if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c869e",
   "metadata": {
    "id": "b45c869e"
   },
   "source": [
    "## Dataset Loading and Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62af8c9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11768,
     "status": "ok",
     "timestamp": 1724758981671,
     "user": {
      "displayName": "Yassine Ouzaina",
      "userId": "01912818402851798301"
     },
     "user_tz": -120
    },
    "id": "62af8c9e",
    "outputId": "5225b8cc-0bcf-48ce-ee95-93dcbcc68f50",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "dataset = load_dataset(\"mychen76/invoices-and-receipts_ocr_v1\")\n",
    "\n",
    "# Model name\n",
    "model_name = \"microsoft/trocr-small-stage1\"\n",
    "\n",
    "# Processor & Model Loading\n",
    "processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Set the decoder start token ID\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "\n",
    "# Ensure pad_token_id is set\n",
    "if processor.tokenizer.pad_token is None:\n",
    "    processor.tokenizer.pad_token = processor.tokenizer.eos_token\n",
    "\n",
    "# Set the pad_token_id in the model configuration\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43588e93",
   "metadata": {
    "id": "43588e93"
   },
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cef80bb",
   "metadata": {
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1724758991607,
     "user": {
      "displayName": "Yassine Ouzaina",
      "userId": "01912818402851798301"
     },
     "user_tz": -120
    },
    "id": "8cef80bb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to resize images\n",
    "def resize_image(image, max_width=1024, max_height=1024):\n",
    "    image.thumbnail((max_width, max_height), Image.Resampling.LANCZOS)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651f25a1",
   "metadata": {
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1724758993451,
     "user": {
      "displayName": "Yassine Ouzaina",
      "userId": "01912818402851798301"
     },
     "user_tz": -120
    },
    "id": "651f25a1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing the dataset with resized images\n",
    "def preprocess_batch(batch):\n",
    "    images = [resize_image(img.convert(\"RGB\")) if isinstance(img, Image.Image) else resize_image(Image.open(img).convert(\"RGB\")) for img in batch['image']]\n",
    "\n",
    "    # Get pixel values from the processor\n",
    "    pixel_values = processor(images, return_tensors=\"pt\").pixel_values.to(device)\n",
    "\n",
    "    # Tokenizing the text data\n",
    "    labels = processor.tokenizer(\n",
    "        batch['parsed_data'],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).input_ids.to(device)\n",
    "\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dabf39",
   "metadata": {
    "id": "49dabf39"
   },
   "source": [
    "## Custom Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36bfa70",
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1724759014680,
     "user": {
      "displayName": "Yassine Ouzaina",
      "userId": "01912818402851798301"
     },
     "user_tz": -120
    },
    "id": "f36bfa70",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom Data Collator for VisionEncoderDecoderModel\n",
    "def collate_fn(batch):\n",
    "    # Ensure pixel_values are stacked as tensors\n",
    "    pixel_values = torch.stack([torch.tensor(item[\"pixel_values\"]) for item in batch])\n",
    "    labels = torch.stack([torch.tensor(item[\"labels\"]) for item in batch])\n",
    "    \n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "F8J3xK0uktPF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "970b171c268f48d9bc2f1856498b150a",
      "ce987a9bd4d14e9cba90c62879374941",
      "25ef4a16484b4c4abea4dbbe64e9c6fe",
      "973a8b375b88400da1c0a4d7d5ec9483",
      "ac62f91e96574317b86791ef3e1171fa",
      "71ab32c27fa24060bea9928e65b7bed6",
      "521387b5b0e54c5182b9b3e802b74484",
      "60d1165a87c74456a69442d6afcb4451",
      "fd20e0895e534f9dae1820a47905987f",
      "6fa4bbab9a06484e8106f5e60858c6c9",
      "e90c498af64d4a4b99bb20308a0f79f2"
     ]
    },
    "id": "F8J3xK0uktPF",
    "outputId": "8640ba58-1050-42be-c237-51cd71471e07",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/2043 [03:57<?, ? examples/s]\n"
     ]
    },
    {
     "ename": "ArrowMemoryError",
     "evalue": "realloc of size 3221225472 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply preprocessing\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m preprocessed_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparsed_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Dataset split\u001b[39;00m\n\u001b[0;32m      5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m preprocessed_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\datasets\\dataset_dict.py:870\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    869\u001b[0m     {\n\u001b[1;32m--> 870\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    889\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    890\u001b[0m     }\n\u001b[0;32m    891\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\datasets\\arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\datasets\\arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    565\u001b[0m }\n\u001b[0;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\datasets\\arrow_dataset.py:3167\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3162\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3163\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3164\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3165\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3166\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3167\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\datasets\\arrow_dataset.py:3581\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3579\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite_table(batch\u001b[38;5;241m.\u001b[39mto_arrow())\n\u001b[0;32m   3580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3581\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3582\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_examples_in_batch\n\u001b[0;32m   3583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m _time \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mPBAR_REFRESH_TIME_INTERVAL:\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\datasets\\arrow_writer.py:569\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[1;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[0;32m    567\u001b[0m         typed_sequence \u001b[38;5;241m=\u001b[39m OptimizedTypedSequence(col_values, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mcol_type, try_type\u001b[38;5;241m=\u001b[39mcol_try_type, col\u001b[38;5;241m=\u001b[39mcol)\n\u001b[0;32m    568\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(pa\u001b[38;5;241m.\u001b[39marray(typed_sequence))\n\u001b[1;32m--> 569\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m \u001b[43mtyped_sequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inferred_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    570\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n\u001b[0;32m    571\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_arrays(arrays, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\datasets\\arrow_writer.py:133\u001b[0m, in \u001b[0;36mTypedSequence.get_inferred_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the inferred feature type.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03mThis is done by converting the sequence to an Arrow array, and getting the corresponding\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mfeature type.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    FeatureType: inferred feature type of the sequence.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type \u001b[38;5;241m=\u001b[39m generate_from_arrow_type(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\pyarrow\\array.pxi:248\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\pyarrow\\array.pxi:112\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\datasets\\arrow_writer.py:193\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     trying_cast_to_python_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# use smaller integer precisions if possible\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrying_int_optimization:\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\pyarrow\\array.pxi:368\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\pyarrow\\array.pxi:42\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\pyarrow\\error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Yassine\\Downloads\\E-Learning\\fine_tuned_trocr_base_handwritten_OCRBench\\ocr_env\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: realloc of size 3221225472 failed"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "preprocessed_dataset = dataset.map(preprocess_batch, batched=True, remove_columns=['id', 'parsed_data', 'raw_data'])\n",
    "\n",
    "# Dataset split\n",
    "train_dataset = preprocessed_dataset['train']\n",
    "eval_dataset = preprocessed_dataset['valid']\n",
    "test_dataset = preprocessed_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c209fb-ef1c-48f2-99ec-75b0e6c793f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./trocr_finetuned_model\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    predict_with_generate=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6a6d6-e60e-413d-94a6-8b9a4d4b0797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model locally\n",
    "model.save_pretrained(\"./trocr_finetuned_model\")\n",
    "processor.save_pretrained(\"./trocr_finetuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c58cf7-f1be-4ffe-823d-1acd95423b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ocr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "25ef4a16484b4c4abea4dbbe64e9c6fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60d1165a87c74456a69442d6afcb4451",
      "max": 2043,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd20e0895e534f9dae1820a47905987f",
      "value": 0
     }
    },
    "521387b5b0e54c5182b9b3e802b74484": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60d1165a87c74456a69442d6afcb4451": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fa4bbab9a06484e8106f5e60858c6c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71ab32c27fa24060bea9928e65b7bed6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "970b171c268f48d9bc2f1856498b150a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce987a9bd4d14e9cba90c62879374941",
       "IPY_MODEL_25ef4a16484b4c4abea4dbbe64e9c6fe",
       "IPY_MODEL_973a8b375b88400da1c0a4d7d5ec9483"
      ],
      "layout": "IPY_MODEL_ac62f91e96574317b86791ef3e1171fa"
     }
    },
    "973a8b375b88400da1c0a4d7d5ec9483": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fa4bbab9a06484e8106f5e60858c6c9",
      "placeholder": "​",
      "style": "IPY_MODEL_e90c498af64d4a4b99bb20308a0f79f2",
      "value": " 0/2043 [00:00&lt;?, ? examples/s]"
     }
    },
    "ac62f91e96574317b86791ef3e1171fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce987a9bd4d14e9cba90c62879374941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71ab32c27fa24060bea9928e65b7bed6",
      "placeholder": "​",
      "style": "IPY_MODEL_521387b5b0e54c5182b9b3e802b74484",
      "value": "Map:   0%"
     }
    },
    "e90c498af64d4a4b99bb20308a0f79f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd20e0895e534f9dae1820a47905987f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
